package uk.gov.companieshouse.requestrefund.consumer.kafka;

import static org.assertj.core.api.Assertions.assertThat;
import static uk.gov.companieshouse.requestrefund.consumer.kafka.KafkaUtils.ERROR_TOPIC;
import static uk.gov.companieshouse.requestrefund.consumer.kafka.KafkaUtils.INVALID_TOPIC;
import static uk.gov.companieshouse.requestrefund.consumer.kafka.KafkaUtils.MAIN_TOPIC;
import static uk.gov.companieshouse.requestrefund.consumer.kafka.KafkaUtils.RETRY_TOPIC;

import java.io.ByteArrayOutputStream;
import java.time.Duration;
import java.util.Collections;
import java.util.Properties;

import org.apache.avro.io.DatumWriter;
import org.apache.avro.io.Encoder;
import org.apache.avro.io.EncoderFactory;
import org.apache.avro.reflect.ReflectDatumWriter;
import org.apache.kafka.clients.admin.AdminClient;
import org.apache.kafka.clients.admin.NewTopic;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.KafkaConsumer;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.junit.jupiter.api.BeforeEach;
import org.junit.jupiter.api.Test;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.boot.test.context.SpringBootTest;
import org.springframework.kafka.test.utils.KafkaTestUtils;
import org.springframework.test.context.DynamicPropertyRegistry;
import org.springframework.test.context.DynamicPropertySource;
import org.springframework.test.context.bean.override.mockito.MockitoBean;

import uk.gov.companieshouse.requestrefund.consumer.service.RefundRequestServiceRouter;

@SpringBootTest
class ConsumerInvalidPayloadExceptionIT extends AbstractKafkaIT {

    @Autowired
    private KafkaConsumer<String, byte[]> testConsumer;

    @Autowired
    private KafkaProducer<String, byte[]> testProducer;

    @MockitoBean
    private RefundRequestServiceRouter refundRequestServiceRouter;

    @DynamicPropertySource
    static void props(DynamicPropertyRegistry registry) {
        registry.add("steps", () -> 1);
    }

    @BeforeEach
    public void setupTopicsAndDrain() throws Exception {
        // Explicitly create topics before each test
        Properties props = new Properties();
        props.put("bootstrap.servers", kafka.getBootstrapServers());
        try (AdminClient adminClient = AdminClient.create(props)) {
            adminClient.createTopics(Collections.singletonList(new NewTopic(MAIN_TOPIC, 1, (short) 1))).all().get();
            adminClient.createTopics(Collections.singletonList(new NewTopic(RETRY_TOPIC, 1, (short) 1))).all().get();
            adminClient.createTopics(Collections.singletonList(new NewTopic(ERROR_TOPIC, 1, (short) 1))).all().get();
            adminClient.createTopics(Collections.singletonList(new NewTopic(INVALID_TOPIC, 1, (short) 1))).all().get();
        } catch( Exception e) {
            // Topics probably already exist, ignore
        }
        testConsumer.poll(Duration.ofMillis(1000));
    }

    @Test
    void testPublishToFilingHistoryInvalidMessageTopicIfInvalidDataDeserialised() throws Exception {
        // given
        ByteArrayOutputStream outputStream = new ByteArrayOutputStream();
        Encoder encoder = EncoderFactory.get().directBinaryEncoder(outputStream, null);
        DatumWriter<String> writer = new ReflectDatumWriter<>(String.class);
        writer.write("bad data", encoder);

        // when
        testProducer.send(new ProducerRecord<>(MAIN_TOPIC, 0, System.currentTimeMillis(),
                "key", outputStream.toByteArray()));

        // then
        ConsumerRecords<?, ?> consumerRecords = KafkaTestUtils.getRecords(testConsumer, Duration.ofMillis(10000L), 2);
        assertThat(KafkaUtils.noOfRecordsForTopic(consumerRecords, MAIN_TOPIC)).isOne();
        assertThat(KafkaUtils.noOfRecordsForTopic(consumerRecords, RETRY_TOPIC)).isZero();
        assertThat(KafkaUtils.noOfRecordsForTopic(consumerRecords, ERROR_TOPIC)).isZero();
        assertThat(KafkaUtils.noOfRecordsForTopic(consumerRecords, INVALID_TOPIC)).isOne();
    }
}
